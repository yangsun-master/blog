<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  
<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-146656651-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->


  
  <title>Azure SQL Data Warehouse Deep Dive | LcodeJ</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Azure SQL Data Warehouse deep dive, including architecture, performance, distribution, and columnstore index.">
<meta name="keywords" content="data">
<meta property="og:type" content="article">
<meta property="og:title" content="Azure SQL Data Warehouse Deep Dive">
<meta property="og:url" content="https://www.lcodej.com/blog/2019/09/13/azure-sql-data-warehouse-deep-dive/index.html">
<meta property="og:site_name" content="LcodeJ">
<meta property="og:description" content="Azure SQL Data Warehouse deep dive, including architecture, performance, distribution, and columnstore index.">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://www.lcodej.com/blog/2019/09/13/azure-sql-data-warehouse-deep-dive/azure-sql-data-warehouse-architecture.png">
<meta property="og:image" content="https://www.lcodej.com/blog/2019/09/13/azure-sql-data-warehouse-deep-dive/distribution.png">
<meta property="og:image" content="https://www.lcodej.com/blog/2019/09/13/azure-sql-data-warehouse-deep-dive/azure-sql-data-warehouse-scale.png">
<meta property="og:image" content="https://www.lcodej.com/blog/2019/09/13/azure-sql-data-warehouse-deep-dive/columnstore-index.png">
<meta property="og:image" content="https://www.lcodej.com/blog/2019/09/13/azure-sql-data-warehouse-deep-dive/btree-index.png">
<meta property="og:image" content="https://www.lcodej.com/blog/2019/09/13/azure-sql-data-warehouse-deep-dive/sisd.png">
<meta property="og:image" content="https://www.lcodej.com/blog/2019/09/13/azure-sql-data-warehouse-deep-dive/simd.png">
<meta property="og:image" content="https://www.lcodej.com/blog/2019/09/13/azure-sql-data-warehouse-deep-dive/avxplus.png">
<meta property="og:updated_time" content="2019-11-20T00:50:17.148Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Azure SQL Data Warehouse Deep Dive">
<meta name="twitter:description" content="Azure SQL Data Warehouse deep dive, including architecture, performance, distribution, and columnstore index.">
<meta name="twitter:image" content="https://www.lcodej.com/blog/2019/09/13/azure-sql-data-warehouse-deep-dive/azure-sql-data-warehouse-architecture.png">
  
    <link rel="alternate" href="/blog/atom.xml" title="LcodeJ" type="application/atom+xml">
  
  
    <link rel="icon" href="/blog/images/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/blog/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/blog/" id="logo">LcodeJ</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/blog/">Home</a>
        
          <a class="main-nav-link" href="/blog/archives">Archives</a>
        
          <a class="main-nav-link" href="/blog/about">About</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/blog/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://www.lcodej.com/blog"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-azure-sql-data-warehouse-deep-dive" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/2019/09/13/azure-sql-data-warehouse-deep-dive/" class="article-date">
  <time datetime="2019-09-13T23:26:05.000Z" itemprop="datePublished">2019-09-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Azure SQL Data Warehouse Deep Dive
    </h1>
  

        
  <div class="article-updated">
    Last updated: <time datetime="2019-11-20T00:50:17.148Z" itemprop="dateModified">2019-11-19</time>
  </div>

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>My recent project uses Azure SQL Data Warehouse. The performance is good. I’m wondering how the Azure SQL Data Warehouse is designed compared to traditional SQL Server Database, and how the performance is improved? Let’s take a deep dive.</p>
<h3 id="Azure-SQL-Data-Warehouse-Architecture"><a href="#Azure-SQL-Data-Warehouse-Architecture" class="headerlink" title="Azure SQL Data Warehouse Architecture"></a>Azure SQL Data Warehouse Architecture</h3><p>Azure SQL Data Warehouse is a distributed computing system. It isn’t a collection of computers which run SQL Server and operate partial of the data. Actually, Azure SQL Data Warehouse has a better design. BTW, it’s big data, but it’s not MapReduce.</p>
<img src="/blog/2019/09/13/azure-sql-data-warehouse-deep-dive/azure-sql-data-warehouse-architecture.png" title="Azure SQL Data Warehouse Architecture">

<p>References:</p>
<ul>
<li><a href="https://azure.microsoft.com/en-us/blog/adaptive-caching-powers-azure-sql-data-warehouse-performance-gains/" target="_blank" rel="noopener">Adaptive caching powers Azure SQL Data Warehouse performance gains</a></li>
<li><a href="https://azure.microsoft.com/en-us/blog/lightning-fast-query-performance-with-azure-sql-data-warehouse/" target="_blank" rel="noopener">Lightning fast query performance with Azure SQL Data Warehouse</a></li>
</ul>
<h4 id="Storage-and-compute-are-decoupled"><a href="#Storage-and-compute-are-decoupled" class="headerlink" title="Storage and compute are decoupled"></a>Storage and compute are decoupled</h4><p>Storage and compute are decoupled. The compute node doesn’t manage the storage. Instead, the compute node is attached to the storage. It means we can scale up/down compute independently. There is no limitation on storage capacity. And we don’t pay for the storage. We only pay for compute. If we want to improve performance, we can allocated more compute nodes, and attach them to the storage. If we want to save money, we can reduce the compute nodes. One interesting thing is we can reduce to zero, we pay nothing, but we can’t access the data. It doesn’t mean we lost data, once we re-attach the compute nodes, we can access the data again. We call it pause/resume the data warehouse. It’s quite flexible. </p>
<p>Reference:</p>
<ul>
<li><a href="https://docs.microsoft.com/en-us/azure/sql-data-warehouse/massively-parallel-processing-mpp-architecture" target="_blank" rel="noopener">Massively parallel processing (MPP) architecture</a></li>
</ul>
<h4 id="Distribution"><a href="#Distribution" class="headerlink" title="Distribution"></a>Distribution</h4><p>There’s a magic number: <strong>60</strong>. Azure SQL Data Warehouse always has 60 distributions. In other words, it divides the data into 60 pieces, the compute node process one or more pieces of the data. If we want to improve the performance, we pay for more compute nodes, and process data in parallel. For example, we have one compute node, the compute node need process all of the 60 distributions. If we have two compute nodes, each one process 30 distributions and they work in parallel. The performance is improved. However, it doesn’t mean adding more compute nodes always improve performance. Another important factor is how the data distributed. If distribution is unbalanced, some distribution has more, some has less, the compute time is the longest time of the compute node who process the most heavy distribution.  </p>
<p>Azure SQL Data Warehouse has two distribution algorithms: hash and round-robin. (Note: the distribution strategy of Azure Data Warehouse is different from MapReduce.)</p>
<ul>
<li>Hash: using a deterministic hashing function to assign a row to 1 of the 60 distributions.</li>
<li>Round-robin: distribute rows evenly across all distributions.</li>
</ul>
<p>Hash distributed table:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> [dbo].[FactOrder]</span><br><span class="line">(</span><br><span class="line">    [OrderKey]            <span class="built_in">int</span>          <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">    [ProductKey]          <span class="built_in">int</span>          <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">    [Quantity]            <span class="built_in">smallint</span>     <span class="keyword">NOT</span> <span class="literal">NULL</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">WITH</span></span><br><span class="line">(</span><br><span class="line">    CLUSTERED COLUMNSTORE <span class="keyword">INDEX</span>,</span><br><span class="line">    DISTRIBUTION = <span class="keyword">HASH</span>([ProductKey])</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>Round-robin distributed table:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> [dbo].[FactOrder]</span><br><span class="line">(</span><br><span class="line">    [OrderKey]            <span class="built_in">int</span>          <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">    [ProductKey]          <span class="built_in">int</span>          <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">    [Quantity]            <span class="built_in">smallint</span>     <span class="keyword">NOT</span> <span class="literal">NULL</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">WITH</span></span><br><span class="line">(</span><br><span class="line">    CLUSTERED COLUMNSTORE <span class="keyword">INDEX</span>,</span><br><span class="line">    DISTRIBUTION = ROUND_ROBIN</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>Round-robin is OK, if the scenario is simple. But in real world, we use Hash to optimize the distribution. And it’s the only way we can control the distribution. Choosing the correct hash column is critical for performance. Choosing hash column isn’t difficult. We can start from our business scenario. For example, which column is used to join two tables, which column is frequently used in group by clause. The optimization goal is to minimize the data movement. In the two tables joining scenario, the hash column is the joining column, the rows of the two tables share the same joining key are distributed to the same compute node. Otherwise, data movement is required.  </p>
<img src="/blog/2019/09/13/azure-sql-data-warehouse-deep-dive/distribution.png" title="Distribution">  
<img src="/blog/2019/09/13/azure-sql-data-warehouse-deep-dive/azure-sql-data-warehouse-scale.png" title="Azure SQL Data Warehouse Scale">  

<p>The hash distribution has limitations. One limitation is the data skew problem. When data is not distribute evenly, scale up computing can’t efficiently help the performance. Another limitation is we can only have one hash column, if the business scenario requires more columns, data movement is required.</p>
<p>Reference:</p>
<ul>
<li><a href="https://docs.microsoft.com/en-us/azure/sql-data-warehouse/memory-and-concurrency-limits" target="_blank" rel="noopener">Memory and concurrency limits for Azure SQL Data Warehouses</a></li>
<li><a href="https://docs.microsoft.com/en-us/azure/sql-data-warehouse/sql-data-warehouse-tables-distribute" target="_blank" rel="noopener">Guidance for designing distributed tables in Azure SQL Data Warehouse</a></li>
<li><a href="https://docs.microsoft.com/en-us/sql/t-sql/statements/create-table-azure-sql-data-warehouse" target="_blank" rel="noopener">CREATE TABLE (Azure SQL Data Warehouse)</a></li>
</ul>
<h3 id="Columnstore-Index"><a href="#Columnstore-Index" class="headerlink" title="Columnstore Index"></a>Columnstore Index</h3><p>Columnstore index is a new method to solve the problem how data is physically stored and how data is indexed.  </p>
<p>A data table is logically organized with rows and columns. The tradition method physically stores data by row. The new method physically store data by column. Wait, the columns are determined, but rows are not. How it works? The data table is divided by columns. Columns are separately stored. A column is a sequence of values. In addition, the sequence is divided into groups, and each group is compressed. A column’s physical representation is a sequence of compressed groups. Why it’s good? It’s because the data warehouse scenario is analysis. The analysis is always column focused. For example, we want to calculate the total sales amount. The data warehouse just load the “sales amount” column from physical media, decompress the data, and calculate the sum. The process is compact, only the column we cared are loaded into memory, not the whole row. The compression is important, it saves the I/O cost (mostly, I/O is the bottleneck). The compression is also efficient, since the values in a column are belong to the same business domain, so they’re similar, and similar values have high compress rate. The group size is fixed, it’s 1,048,576 (another magic number: 2^20). The group size is carefully decided, large enough to improve compression rates, and small enough to benefit from in-memory operations. Decompress can be optimized by CPU AVX technologies, like the video encoding/decoding technologies.  </p>
<img src="/blog/2019/09/13/azure-sql-data-warehouse-deep-dive/columnstore-index.png" title="Columnstore Index">  

<p>For a comparison, let’s take a look at the tradition method. Data is stored by row physically. Index is created on column. The index is implemented by B-tree. The tree node contains the key, the index of the row, and pointers to the child tree nodes. Time complexity of searching a row is O(log(n)). For the same scenario, “calculate the total sales amount”, load the index into memory, traversal the tree, and calculate the sum of all the keys. The process isn’t as efficient as columnstore index, when the data size is large.</p>
<img src="/blog/2019/09/13/azure-sql-data-warehouse-deep-dive/btree-index.png" title="B-Tree Index">  

<p>Reference:</p>
<ul>
<li><a href="https://docs.microsoft.com/en-us/sql/relational-databases/indexes/columnstore-indexes-overview?view=sql-server-2017" target="_blank" rel="noopener">Columnstore indexes: Overview</a></li>
<li><a href="https://www.geeksforgeeks.org/indexing-in-databases-set-1/" target="_blank" rel="noopener">Indexing in Databases | Set 1</a></li>
</ul>
<h3 id="Hardware-innovation"><a href="#Hardware-innovation" class="headerlink" title="Hardware innovation"></a>Hardware innovation</h3><h4 id="MVMe-SSD"><a href="#MVMe-SSD" class="headerlink" title="MVMe SSD"></a>MVMe SSD</h4><p>I/O bandwidth is critical. Azure SQL Data Warehouse Gen 2 takes advantage of <a href="https://amzn.to/2NN3kz0" target="_blank" rel="noopener">MVMe SSD</a>, which offer up to 2 2GB/s of local I/O bandwidth.<br>Here’s the read/write speed comparisons between HDD, SATA SSD and MVMe SSD.</p>
<ul>
<li>7200RPM SATA HDD read/write speed is around 100MB/s</li>
<li>SATA SSD read/write speed is around 500MB/s</li>
<li><a href="https://amzn.to/2NN3kz0" target="_blank" rel="noopener">MVMe SSD</a> read speed is up to 3,500MB/s</li>
</ul>
<h4 id="AVX"><a href="#AVX" class="headerlink" title="AVX"></a>AVX</h4><p>Azure SQL Data Warehouse operates directly over compressed data, which take the advantage of the CPU technology: AVX.<br><a href="https://en.wikipedia.org/wiki/Advanced_Vector_Extensions" target="_blank" rel="noopener">Advanced Vector Extensions (AVX)</a> uses 16 YMM registers to perform single instruction on multiple pieces of data (<a href="https://en.wikipedia.org/wiki/SIMD" target="_blank" rel="noopener">SIMD</a>). The register is increased to 256 bits from 128 bits. New instructions are added.  </p>
<img src="/blog/2019/09/13/azure-sql-data-warehouse-deep-dive/sisd.png" title="SISD(Single Instruction Single Data)">  
<img src="/blog/2019/09/13/azure-sql-data-warehouse-deep-dive/simd.png" title="SIMD(Single Instruction Multiple Data)">  
<img src="/blog/2019/09/13/azure-sql-data-warehouse-deep-dive/avxplus.png" title="AVX plus operation">  

<p>Reference:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/SIMD" target="_blank" rel="noopener">SIMD</a></li>
<li><a href="https://www.codingame.com/playgrounds/283/sse-avx-vectorization/what-is-sse-and-avx" target="_blank" rel="noopener">SSE &amp; AVX Vectorization</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://www.lcodej.com/blog/2019/09/13/azure-sql-data-warehouse-deep-dive/" data-id="ck36rvxdg000upwlvcf5ldfbu" class="article-share-link">Share</a>
      
        <a href="https://www.lcodej.com/blog/2019/09/13/azure-sql-data-warehouse-deep-dive/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/data/">data</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/blog/2019/11/19/exploratory-data-analysis-in-python/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Exploratory data analysis in python
        
      </div>
    </a>
  
  
    <a href="/blog/2019/09/02/hardware/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Hardware</div>
    </a>
  
</nav>

  
</article>


<section id="comments">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>
</section>
        
          <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">About</h3>
  <div class="widget">
    <ul>
      <li><a href="/blog/about">About me</a></li>
    </ul>
  </div>
</div>

  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/data/">data</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/hardware/">hardware</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/tool/">tool</a><span class="tag-list-count">3</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/blog/2019/11/19/exploratory-data-analysis-in-python/">Exploratory data analysis in python</a>
          </li>
        
          <li>
            <a href="/blog/2019/09/13/azure-sql-data-warehouse-deep-dive/">Azure SQL Data Warehouse Deep Dive</a>
          </li>
        
          <li>
            <a href="/blog/2019/09/02/hardware/">Hardware</a>
          </li>
        
          <li>
            <a href="/blog/2019/08/30/visual-studio-code-shortcuts/">Visual Studio Code Shortcuts</a>
          </li>
        
          <li>
            <a href="/blog/2019/08/26/customize-hexo-blog/">Customize Hexo blog</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/blog/archives/2019/11/">November 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/blog/archives/2019/09/">September 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/blog/archives/2019/08/">August 2019</a><span class="archive-list-count">4</span></li></ul>
    </div>
  </div>


  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Yang Sun<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/blog/" class="mobile-nav-link">Home</a>
  
    <a href="/blog/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/blog/about" class="mobile-nav-link">About</a>
  
</nav>
    
<script>
  var disqus_shortname = 'lcodej';
  
  var disqus_url = 'https://www.lcodej.com/blog/2019/09/13/azure-sql-data-warehouse-deep-dive/';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/blog/fancybox/jquery.fancybox.css">
  <script src="/blog/fancybox/jquery.fancybox.pack.js"></script>


<script src="/blog/js/script.js"></script>



  </div>
</body>
</html>